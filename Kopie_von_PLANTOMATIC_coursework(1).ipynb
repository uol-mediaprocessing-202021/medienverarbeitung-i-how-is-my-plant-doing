{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kopie_von_PLANTOMATIC_coursework.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hp_M7EMFQTCF"
      },
      "source": [
        "**P L A N T O M A T I C** - COURSEWORK\n",
        "\n",
        "---\n",
        "\n",
        "*Kian Lütke, Carsten Montag, Johannes Maximilian Stürenburg*\n",
        "\n",
        "This document outlines the documentation and progress journal of group I of the class _Media-Processing_. This work is divided in several chapters. Each section will be presented with executable code examples which will be - if run in the correct order - in the end illustrate the whole project together. \n",
        "\n",
        "The same code will be appended in the appendix to be run alone; not tied to this course work.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFJa8RtR7Q8b"
      },
      "source": [
        "# 1. Introduction\n",
        "\n",
        "## 1.1. Motivation\n",
        "\n",
        "This coursework is part of a multi-project class called _Mediaprocessing_ taught by Prof. Dr. techn. Susanne Boll-Westermann and Dr.-Ing. Larbi Abdenebaoui. During the introduction weeks several Projects were introduced to pick from. As one of the group members does grow herbs at home the obvious choice here is the project _How Is My Plant Doing_. To briefly explain the goal subject: An image of a plant should be analyzed to tell whether the plant needs watering or not.  \n",
        "\n",
        "## 1.2. Case/Goal\n",
        "\n",
        "The main goal of the project is to distinguish between two different plants and classify them to get an idea about their current state. \n",
        "\n",
        "A case was developed to fund the classwork’s structure upon:\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/uol-mediaprocessing-202021/medienverarbeitung-i-how-is-my-plant-doing/blob/master/figures/1-concept.png?raw=1\" height=\"300px\" alt=\"Concept\" id=\"fig-concept\">\n",
        "\n",
        "**Fig 1** - Rough Concept\n",
        "\n",
        "The idea outlines that some sort of robot will take care of a kitchen-garden. The robot should move from plant to plant taking pictures and processing the images. Afterwards the images will be analyzed and classified. The robot decides whether the plant needs to be watered or not. In the letter case a message will be send to the owner’s mobile device to inform about the plants state. The message could contain the image of the plant itself as well. As there is no access to a real robot which actually is able to move. This project will make use of a stationary Raspberry Pi computer with a camera attached to it. The Raspberry Pi will then take a set of pictures every hour and evaluate the plant-state directly.    \n",
        "\n",
        "## 1.3. Methodology\n",
        "This work is divided in two main sections: The feature analysis part and the machine learning part. The first part will cover how images were gathered and how these images will be processed in order to prepare them for the machine learning training. In the second part the actual learning of the machine learning algorithms.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKoiNLFw7zYC"
      },
      "source": [
        "# 2. Feature Analysis\n",
        "\n",
        "## 2.1. Data Gathering\n",
        "\n",
        "This section describes the process of acquiring images of the plants. The first approach was to use a mirrorless system-camera to take thousands of pictures.\n",
        "\n",
        "<img src=\"https://github.com/uol-mediaprocessing-202021/medienverarbeitung-i-how-is-my-plant-doing/blob/master/figures/2-dslm.png?raw=1\" height=\"300px\" alt=\"Concept\" id=\"fig-dslm\">\n",
        "\n",
        "**Fig 2** - Picture taken with a DSLM Full Frame Camera [Sony a7 – 50mm/f5.6]\n",
        "\n",
        "As seen in Figure 2 the results are astonishing. The downside comes with the amount of time needed to take all the needed images. Taking approx. 1200 images took around 3 hours. So, the idea came up to take short videos of the plant and extract single frames to process them as images. For example, a short clip of 30 seconds could generate 1800 images if every fame is used.\n",
        "\n",
        "60 FPS Footage: 30 (seconds) * 60 (fps) = 1800\n",
        "\n",
        "The drawback here is the blurriness of extracted frames. A solution will be discussed in the next section.\n",
        "\n",
        "**Choosing the right plants**\n",
        "\n",
        "At the beginning of the projects two different plants were chosen: Basil and German mint. During this project we decided – because of the difficulties to distinguish between this two plants  - to switch from mint to chives. We decided to create a diary and observe the plants in different states. More on that in the next chapter.\n",
        "\n",
        "## 2.2. The Plant-Diary\n",
        "\n",
        "> Date | State of Chive | Sate of Basil | Video Chive | Video Basil | Notes | Time passed (h) since recovery \n",
        "> --- | --- | --- | --- | --- | --- | ---\n",
        "> 09.12.20 12:30 | New | Needs watering | ------------------------------------------------------ | ------------------------------------------------------ | Last watering | n/a\n",
        "> 09.12.20 17:00 | No change visible | Fully recovered | <img src=\"https://github.com/uol-mediaprocessing-202021/medienverarbeitung-i-how-is-my-plant-doing/blob/master/gif/schnittlauch1.gif?raw=1\" height=\"100\">  | <img src=\"https://github.com/uol-mediaprocessing-202021/medienverarbeitung-i-how-is-my-plant-doing/blob/master/gif/basilikum1.gif?raw=1\" height=\"100\"> |  | 0\n",
        "> 10.12.20 12:10 | No change visible | No change visible | <img src=\"https://github.com/uol-mediaprocessing-202021/medienverarbeitung-i-how-is-my-plant-doing/blob/master/gif/schnittlauch2.gif?raw=1\" height=\"100\">  | <img src=\"https://github.com/uol-mediaprocessing-202021/medienverarbeitung-i-how-is-my-plant-doing/blob/master/gif/basilikum2.gif?raw=1\" height=\"100\"> |  | 19\n",
        "> 10.12.20 19:50 | Visible hanging of the leaves | Pot is very light, will need water soon | <img src=\"https://github.com/uol-mediaprocessing-202021/medienverarbeitung-i-how-is-my-plant-doing/blob/master/gif/schnittlauch3.gif?raw=1\" height=\"100\">  | <img src=\"https://github.com/uol-mediaprocessing-202021/medienverarbeitung-i-how-is-my-plant-doing/blob/master/gif/basilikum3.gif?raw=1\" height=\"100\"> |  | 27\n",
        "> 11.12.20 11:50 | Even more hanging | Leaves also start hanging; pot is very light; needs water | <img src=\"https://github.com/uol-mediaprocessing-202021/medienverarbeitung-i-how-is-my-plant-doing/blob/master/gif/schnittlauch4.gif?raw=1\" height=\"100\">  | <img src=\"https://github.com/uol-mediaprocessing-202021/medienverarbeitung-i-how-is-my-plant-doing/blob/master/gif/basilikum4.gif?raw=1\" height=\"100\"> |  | 43\n",
        "> 12.12.20 09:10 | Still green; growing fast | End of experiment; final state is reached | <img src=\"https://github.com/uol-mediaprocessing-202021/medienverarbeitung-i-how-is-my-plant-doing/blob/master/gif/schnittlauch5.gif?raw=1\" height=\"100\">  | <img src=\"https://github.com/uol-mediaprocessing-202021/medienverarbeitung-i-how-is-my-plant-doing/blob/master/gif/basilikum5.gif?raw=1\" height=\"100\"> | Basil gets watered | 64\n",
        "> 13.12.20 14:30 | Still hanging | Fully recovered again | <img src=\"https://github.com/uol-mediaprocessing-202021/medienverarbeitung-i-how-is-my-plant-doing/blob/master/gif/schnittlauch6.gif?raw=1\" height=\"100\">  | <img src=\"https://github.com/uol-mediaprocessing-202021/medienverarbeitung-i-how-is-my-plant-doing/blob/master/gif/basilikum6.gif?raw=1\" height=\"100\"> | Chive gets watered | 93\n",
        "> 14.12.20 12:30 | Still the same development | aborted | <img src=\"https://github.com/uol-mediaprocessing-202021/medienverarbeitung-i-how-is-my-plant-doing/blob/master/gif/schnittlauch7.gif?raw=1\" height=\"100\">  | n/a |  | 116\n",
        "> 16.12.20 08:30 | Still the same development | aborted | <img src=\"https://github.com/uol-mediaprocessing-202021/medienverarbeitung-i-how-is-my-plant-doing/blob/master/gif/schnittlauch8.gif?raw=1\" height=\"100\">  | n/a | Experiment aborted | 159\n",
        "\n",
        "## 2.3. Pre-Processing\n",
        "\n",
        "## 2.4. The Robot aka Raspberry Pi\n",
        "\n",
        "## 2.5. Telegram Bot\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eB8G4yjP5_q"
      },
      "source": [
        "# 3. Machine Learning\n",
        "\n",
        "Machine Learning according to Zhang (1999) is a model that uses experience to generate an algorithm that performs an automated mapping from inputs to outputs. In this project the experience is the training pictures of plants with corresponding states. The mapping that need to be done in the future is determining the object and state of a picture that will be the input of the machine learning model. \n",
        "\n",
        "## 3.1 Choosing the fitting machine learning approach \n",
        "\n",
        "The goal of this project is to differentiate between two different plants and then determining the state of the plant, the state in this case is the hydration \n",
        "We use the supervised learning approach for image recognition in this project, we chose this approach because of the relative simplicity and the adecuacy of the implementation. We created a database of four types of pictures.\n",
        "\n",
        "**1:** Basil in need of watering\n",
        "\n",
        "**2:** Basil in good condition\n",
        "\n",
        "**3:** Parsley in need of watering\n",
        "\n",
        "**4:** Parsley in good condition\n",
        "\n",
        "These pictures are labelled according to the state, these pictures are then used for the training of the neural network. If we look at Zhangs definition of machine learning, this database is the experience the machine learning model will use to create a function to map the inputs. If the training is successful, the model would then get a picture of a plant it has not seen before, and then determine the state of the object recognized in this picture.\n",
        "\n",
        "## 3.2 Problems\n",
        "\n",
        "We encountered different problems while developing and training the model.\n",
        "\n",
        "## 3.2.1 Performance \n",
        "\n",
        "When first implementing the convolutional neural network, we used the original size of the image which was taken with a high-quality camera. A doubling in size of the image means a quadrupling of the input data. The training is only possible with a very small batch size and even then takes a considerable amount of time for training, the obvious solution was a reduction in size of the input pictures, which greatly increased the performance. Analogous to the increase of the image size, a decrease of the image size by the factor of 2 means an input size reduction by the factor 4. The question here was the final accuracy of the convolutional neural network if the image size is greatly reduced. We decreased the size of the image just so far that the training of the model is performed in an acceptable timeframe.\n",
        "\n",
        "## 3.2.2 Hardware\n",
        "\n",
        "Without using the generator, even a small batch size will cause an error in the programming environment because the amount of RAM used is greater than the amount available. This is because all input pictures of the batch will be loaded into the ram for training, with a large amount of training data this limitation is reached very quickly.\n",
        "\n",
        "The training speed could be enhanced by using hardware that is specialized on using tensorflow\n",
        "\n",
        "## 3.2.3 Generalization\n",
        "\n",
        "The goal of this CNN is the the image recognition of a plant and its state, for this a labelled dataset for training is needed. A major problem is the needed generalization of the model, this presupposed a very large variety in the learning dataset. Since we used our own plants the variety is not as big, this means that the neural network could just memorize the plants that we used for training. In this case the model could only recognize the used plants reliably but not new data for predictions.\n",
        "\n",
        "##3.3 Types of Layers in a CNN\n",
        "\n",
        "A convolutional neural network for image recognition can be composed of multiple types of layers. Typical layers are the Conv2d Layer, the MaxPooling Layer, a Flatten Layer and a Dense Layer. We will shortly describe\n",
        "\n",
        "\n",
        "**Conv2D Layer**\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1320/1*LT0l-KXw5FXIkcGVl-KXlQ.gif\" height=\"200x\" alt=\"Concept\" id=\"fig-dslm\">\n",
        "Quelle: https://towardsdatascience.com/conv2d-to-finally-understand-what-happens-in-the-forward-pass-1bbaafb0b148\n",
        "\n",
        "\n",
        "**MaxPooling Layer**\n",
        "\n",
        "<img src=\"https://developers.google.com/machine-learning/practica/image-classification/images/maxpool_animation.gif\" height=\"200x\" alt=\"Concept\" id=\"fig-dslm\">\n",
        "Quelle: https://developers.google.com/machine-learning/practica/image-classification/convolutional-neural-networks\n",
        "\n",
        "The MaxPooling Layer \n",
        "\n",
        "**Flattening Layer**\n",
        "\n",
        "<img src=\"https://sds-platform-private.s3-us-east-2.amazonaws.com/uploads/73_blog_image_1.png\n",
        "\" height=\"200x\" alt=\"Concept\" id=\"fig-dslm\">\n",
        "Quelle: https://www.superdatascience.com/blogs/convolutional-neural-networks-cnn-step-3-flattening\n",
        "\n",
        "**Fully Connected Layer**\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1400/1*IWUxuBpqn2VuV-7Ubr01ng.png\n",
        "\" height=\"200x\" alt=\"Concept\" id=\"fig-dslm\">\n",
        "Quelle: https://towardsdatascience.com/the-most-intuitive-and-easiest-guide-for-convolutional-neural-network-3607be47480\n",
        "\n",
        "**Dense Layer**\n",
        "\n",
        "The Dense Layer is a condensation of a previous layer, because of the condensation or the reduction of the neuron count this is called the Dense Layer. If the goal of a CNN is the determination if a the object in a picture ist a dog or a cat, this layer should be composed of two neurons. One of these neurons is symbolically a cat and the other a dog, if the final value of the \"dog-neuron\" is 0.84, this would mean that the object in said picture is a dog with 84% certainty.\n",
        "\n",
        "\n",
        "\n",
        "## 3.4 EfficientNet\n",
        "\n",
        "Das EfficientNet wurde 2019 von Mingxing Tan und Quoc V. Le in der Abhandlung *EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks* vorgestellt. Through repeated scaling this net has state-of-the-art performance and precision in image recognition.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns8HU0c2iAhc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}